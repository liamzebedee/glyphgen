# Implementation Plan: Generative Font Renderer

> Generated by Ralph Planning Mode via OpenProse VM

## Current State

- [x] **Directory structure created** - src/, tests/, data/, networks/, outputs/, fonts/
- [x] **Dependencies defined** - requirements.txt created
- [x] **Config system** - src/config.py with all hyperparameters
- [x] **Utilities** - src/utils.py with device detection, checkpointing
- [x] **Training data generated** - 14,040 samples saved to data/train_dataset.pt (877.7 MB)
- [x] **Training pipeline** - src/train.py with loss functions, training loop, CLI
- [ ] **No model weights** - Ready to train with `python src/train.py --epochs 100`

## Specs Reference

All specs in `specs/`:
- `glyph-network.md` - Neural network architecture
- `training-data.md` - Dataset generation
- `personality-expression.md` - 64-dim style_z
- `context-awareness.md` - prev_char influence
- `inference-performance.md` - <5ms latency
- `readability-guarantees.md` - 95%+ recognition
- `online-learning.md` - REINFORCE updates
- `feedback-collection.md` - Claude evaluation
- `weight-update-strategy.md` - Gradient computation
- `model-persistence.md` - networks/[id]/runs/

---

## Phase 1: Project Foundation (No Dependencies)

### 1.1 Project Structure Setup
- [x] Create `src/` directory with `__init__.py`
- [x] Create `tests/` directory with `__init__.py`
- [x] Create `data/` directory for training data
- [x] Create `networks/` directory for model persistence
- [x] Create `outputs/` directory for demo output
- [x] Create `fonts/` directory for Open Sans

> Note: Using single-file modules per AGENTS.md pattern instead of subdirectories.
> Files: glyphnet.py, generate_dataset.py, train.py, demo.py, online_learn.py

### 1.2 Dependency Management
- [x] Create `requirements.txt` with PyTorch 2.0+, Pillow, numpy, anthropic, etc.

### 1.3 Configuration System
- [x] Create `src/config.py` with all hyperparameters (dataclass-based)
- [x] Create `src/utils.py` with device detection, checkpointing, slugify

### 1.4 Documentation
- [x] Create `AGENTS.md` with project conventions

**Phase 1 COMPLETE** ✓

---

## Phase 2: Data Pipeline (Depends on: Phase 1)

> Note: Tasks 2.1-2.4 were combined into a single `src/generate_dataset.py` file per the single-file module pattern in AGENTS.md.

### 2.1 Font Acquisition
- [x] Font downloaded to `fonts/OpenSans-Regular.ttf`

### 2.2 Character Rendering
- [x] Implemented in `src/generate_dataset.py`:
  - Render single character to 128x128 grayscale PIL Image
  - Center character in canvas with consistent padding
  - Support all 26 lowercase letters (a-z)
  - Validate rendered characters are non-blank

### 2.3 Augmentation Pipeline
- [x] Implemented in `src/generate_dataset.py`:
  - Rotation: [-15, 15] degrees
  - Scale: [0.8, 1.2] factor
  - Translation: [-5, 5] pixels both axes
  - Gaussian blur: kernel sizes [1, 3, 5]
  - Gaussian noise: std [0.01, 0.1]
  - Deterministic with seed control
  - Preserve 128x128 dimensions

### 2.4 Dataset Generation
- [x] Implemented as `src/generate_dataset.py`:
  - Generated 14,040 samples (26 chars x 27 contexts x 20 augmentations)
  - Created tensors: images (14040, 1, 128, 128), prev_chars (14040,), curr_chars (14040,)
  - Saved to `data/train_dataset.pt` (877.7 MB)
  - Reproducible with fixed seed
  - Progress logging included

### 2.5 Dataset Loader
- [x] Implemented `src/dataset.py`:
  - GlyphDataset class wrapping the .pt file
  - create_dataloaders() factory with train/val split
  - create_train_loader() for full dataset without split
  - Configurable batch size, workers, pin_memory
  - Reproducible splits with seed parameter

### 2.6 Data Tests
- [x] Created `tests/test_dataset.py` with 27 tests:
  - Dataset loading and sample access
  - Data shapes (image: 1x128x128, chars: scalar int64)
  - Value ranges (images: [0,1], prev_char: [0,26], curr_char: [1,26])
  - All 26 chars and 27 contexts represented
  - DataLoader creation with train/val split
  - Batch shapes and dtypes
  - Shuffle behavior (train shuffles, val deterministic)
  - Custom batch size and split ratio
  - Reproducibility with fixed seed
  - Data integrity and distribution validation

**Phase 2 COMPLETE** ✓

---

## Phase 3: Core Neural Network (Depends on: Phase 1)

> Note: Per AGENTS.md single-file pattern, implemented as `src/glyphnet.py` instead of separate files in `src/models/`.

### 3.1-3.4 GlyphNetwork Implementation
- [x] Implemented `src/glyphnet.py` with:
  - PrevCharEmbedding: 27 tokens x 32 dims (token 0 = start)
  - CurrCharEmbedding: 27 tokens x 32 dims
  - Input validation for token ranges
  - MLP fusion: 128 -> 256 -> 512 -> 256 -> 512
  - Decoder projection: 512 -> 2048 (reshape to 8x8x32)
  - TransposeConv decoder: 8x8 -> 128x128
  - Channel progression: 32 -> 64 -> 32 -> 16 -> 8 -> 1
  - Sigmoid output in [0, 1]
  - Parameter count: 1,555,777 (within 2.9M limit)
  - Forward: `forward(prev_char, curr_char, style_z) -> (B, 1, 128, 128)`

### 3.5 Model Tests
- [x] Created `tests/test_glyphnet.py` with 27 tests:
  - Input/output shapes (single and batch)
  - Output bounds [0, 1] including extreme styles
  - Input validation (valid ranges, rejects invalid)
  - Style variation produces different outputs
  - Character variation produces different outputs
  - All 26 characters produce distinct outputs
  - prev_char affects output
  - Determinism with fixed seed
  - Batch equals individual processing
  - Parameter count < 2.9M
  - CPU inference < 100ms
  - Edge cases (start token, repetition, not blank/saturated)

**Phase 3 COMPLETE** ✓

---

## Phase 4: Persistence Layer (Depends on: Phase 3)

> Note: Per AGENTS.md single-file pattern, implemented as `src/persistence.py` instead of `src/utils/persistence.py`.

### 4.1 Directory Management
- [x] Implemented `src/persistence.py`:
  - Create `networks/[id]/runs/` directory structure via `ensure_font_dirs()`
  - Font ID validation: `{number}-{name}` pattern, lowercase only via `validate_font_id()`
  - Unique run ID generation (ISO 8601 timestamps with microseconds) via `generate_run_id()`
  - Directory discovery on startup via `list_fonts()` and `list_runs()`

### 4.2 Weight Serialization
- [x] Implemented weight save/load in `src/persistence.py`:
  - `save_model(font_id, model, style_z, sample_image, eval_glyphs, feedback)` -> run_id
  - `load_model(font_id, model, run_id=None)` - defaults to latest run, returns (style_z, metadata)
  - Version metadata in saved files (`weights_version`, `feedback_schema`)
  - Atomic saves via `_atomic_save()` (temp file + rename)
  - Corruption detection on load with clear error messages

### 4.3 Run Management
- [x] Implemented run tracking:
  - `list_fonts()` -> List[str] - sorted alphabetically
  - `list_runs(font_id)` -> List[RunMetadata] - sorted chronologically
  - `get_run_info(font_id, run_id)` -> RunMetadata
  - `get_latest_run(font_id)` -> Optional[RunMetadata]
  - Handle incomplete runs gracefully (missing metadata handled)
  - Additional utilities: `load_feedback()`, `load_sample_image()`, `load_eval_glyphs()`, `export_style_z()`

### 4.4 Persistence Tests
- [x] Created `tests/test_persistence.py` with 42 tests:
  - Font ID validation (valid/invalid patterns)
  - Directory creation and structure
  - Save/load round-trip numerical equivalence (6 decimal places)
  - Run discovery and chronological ordering
  - Corruption detection (corrupted weights, missing keys, corrupted metadata)
  - Concurrent access safety (parallel saves to different fonts)
  - File existence checks and deletion operations
  - RunMetadata serialization/deserialization
  - Style vector export

**Phase 4 COMPLETE** ✓

---

## Phase 5: Training Pipeline (Depends on: Phases 2, 3, 4)

> Note: Per AGENTS.md single-file pattern, implemented as `src/train.py` instead of separate files.

### 5.1 Loss Functions
- [x] Implemented in `src/train.py`:
  - MSE reconstruction loss for pixel values
  - Edge-aware loss using Sobel gradient magnitude
  - Combined loss: `total = recon + edge_weight * edge`

### 5.2 Base Trainer
- [x] Implemented in `src/train.py`:
  - `train_one_epoch()` function with DataLoader iteration
  - AdamW optimizer with configurable weight decay
  - CosineAnnealingWarmRestarts scheduler with warmup
  - Checkpoint saving (best, periodic, final)
  - Loss logging per epoch (total, recon, edge)
  - Device management via `get_device()`

### 5.3 Training Script
- [x] Implemented `src/train.py`:
  - CLI with argparse: `--epochs`, `--resume`, `--output-dir`
  - Config loading from `src/config.py`
  - Dataset initialization via `create_dataloaders()`
  - Model initialization and parameter counting
  - Training execution with validation
  - Final checkpoint saved to `outputs/final_checkpoint.pt`

### 5.4 Training Tests
- [x] Created `tests/test_training.py` with 18 tests:
  - Loss computation (MSE, combined, edge weight)
  - Edge loss shape, positivity, gradient flow
  - Single training step updates weights
  - Validation step doesn't update weights
  - Gradient stability (no NaN/Inf)
  - Loss decreases over steps
  - Checkpoint save/resume round-trip
  - Full training loop runs for 1 epoch

**Phase 5 COMPLETE** ✓

---

## Phase 6: Personality Expression (Depends on: Phase 5)

> Note: Per AGENTS.md single-file pattern, implemented as `src/style.py` instead of `src/models/style.py`.

### 6.1 Style Latent Interface
- [x] Implemented `src/style.py`:
  - StyleVector dataclass: 64-dim float tensor with name
  - Creation methods: zeros(), random(seed, std), from_tensor(), load()
  - Interpolation: interpolate(other, t) for smooth transitions
  - L2 norm operations: norm(), clamp_norm(max), normalize(target)
  - Persistence: save(path), load(path) with multiple format support
  - Utilities: to(device), clone(), perturb(std, seed)
  - Helper functions: create_personality_vectors(), interpolate_personalities()

### 6.2 Personality Definitions
- [x] Personalities defined in `src/config.py`:
  - CONFIG.personalities = ["fruity", "dumb", "aggressive-sans"]
  - create_personality_vectors() generates seeded random vectors per personality
  - No separate YAML needed - config.py is the single source of truth

### 6.3 Personality Tests
- [x] Created `tests/test_style.py` with 53 tests:
  - StyleVector creation (zeros, random, from_tensor) with correct dimensions
  - Validation rejects wrong dimensions, 2D tensors, 0D tensors
  - Norm operations: calculation, clamping, normalization
  - Interpolation: t=0/0.5/1.0, rejects invalid t, smooth transitions
  - Persistence: save/load roundtrip, parent dir creation, legacy formats
  - Operations: to(), clone(), perturb(), equality, repr
  - create_personality_vectors(): creates unique, named, reproducible vectors
  - interpolate_personalities(): correct steps, endpoints match
  - Model integration: zero vector valid, deterministic, different styles differ

**Phase 6 COMPLETE** ✓

---

## Phase 7: Inference Optimization (Depends on: Phase 3)

### 7.1 GPU Optimization
- [ ] Implement `src/inference/engine.py`:
  - CUDA device placement
  - torch.compile() for graph optimization
  - Pre-allocated buffer pool
  - Warmup inference on model load

### 7.2 Batched Inference
- [ ] Implement batch processing:
  - Dynamic batch size support (1-32)
  - Sub-linear per-glyph latency scaling
  - Memory-efficient batch handling

### 7.3 Performance Benchmarks
- [ ] Create `tests/benchmark_inference.py`:
  - Single-glyph latency test (< 5ms on RTX 3090)
  - Batch efficiency test (batch of 8 <= 60% per-glyph latency)
  - Memory usage test (< 500MB single, < 2GB batch of 8)
  - Throughput test (>= 200 glyphs/second)
  - 10,000 consecutive inference stress test

---

## Phase 8: Claude Feedback Integration (Depends on: Phases 4, 6)

### 8.1 Image Encoding
- [ ] Implement `src/evaluation/image_encoding.py`:
  - Convert glyph tensor to PNG bytes
  - Base64 encode for API transmission
  - Validate encoding fidelity

### 8.2 Claude Vision API Client
- [ ] Implement `src/evaluation/claude_feedback.py`:
  - Initialize Anthropic client with API key
  - Send base64 image with personality rating prompt
  - Parse 1-10 ratings from Claude response
  - Handle API errors: timeout, rate limit, auth failure
  - Retry logic with exponential backoff

### 8.3 Feedback Prompt Engineering
- [ ] Create prompts for personality dimensions:
  - Fruity: "Rate how fruity this glyph is (1=minimal, 10=extremely). Consider curves, roundness, playful characteristics."
  - Aggressive: "Rate aggression (1=minimal, 10=extreme). Consider sharp angles, boldness, tension."
  - Additional dimensions as needed

### 8.4 Feedback Storage
- [ ] Implement feedback persistence:
  - Save to `networks/[id]/runs/N_eval_X_glyph-[char]_feedback.txt`
  - JSON format with ratings, timestamp, model metadata
  - Append without overwriting previous feedback

### 8.5 Feedback Tests
- [ ] Create `tests/test_feedback.py`:
  - Test image encoding round-trip
  - Test feedback file creation and format
  - Mock Claude API for deterministic tests
  - Test error handling for API failures

---

## Phase 9: Online Learning (Depends on: Phases 5, 8)

### 9.1 REINFORCE Implementation
- [ ] Implement `src/training/reinforce.py`:
  - `compute_policy_gradient(feedback_scores, style_z, log_probs)` -> gradients
  - Advantage computation: rating - baseline
  - Gradient scaling by advantage

### 9.2 EMA Baseline Tracker
- [ ] Implement `src/training/baseline.py`:
  - Exponential moving average: baseline = alpha * rating + (1-alpha) * baseline
  - Configurable alpha (default 0.9-0.99)
  - Initialization strategy
  - Save/load baseline state

### 9.3 Weight Update Strategy
- [ ] Implement `src/training/weight_updater.py`:
  - Apply gradient updates to style_z and decoder layers
  - Gradient clipping (L2 norm threshold)
  - Learning rate control
  - Update only specified layers (final 2-3 decoder layers)

### 9.4 Online Learning Integration
- [ ] Implement `src/training/online_learner.py`:
  - Full cycle: rating -> advantage -> gradient -> update -> checkpoint
  - Update within 500ms budget
  - Memory overhead < 50MB
  - Checkpoint to `networks/[id]/runs/[run_id]/weights_v[N].pt`
  - Log gradients, losses, weight statistics

### 9.5 Online Learning Tests
- [ ] Create `tests/test_online_learning.py`:
  - Test advantage computation
  - Test baseline EMA convergence
  - Test gradient stability (no NaN/Inf)
  - Test weight update direction matches advantage sign
  - Test checkpoint versioning

---

## Phase 10: Readability Validation (Depends on: Phases 3, 5)

### 10.1 Edge Detection Metrics
- [ ] Implement `src/evaluation/readability.py`:
  - Edge sharpness score via gradient magnitude
  - Mean gradient threshold > 0.7

### 10.2 Glyph Metrics
- [ ] Implement glyph measurement:
  - X-height, cap-height, stroke width
  - Comparison against Open Sans reference (within +/- 15%)

### 10.3 Automated Recognition (Optional)
- [ ] Implement OCR validation:
  - Use pretrained character classifier
  - Validate generated glyphs are recognizable
  - Target: > 95% accuracy

### 10.4 Readability Tests
- [ ] Create `tests/test_readability.py`:
  - Test edge sharpness metric
  - Test glyph metrics within tolerance
  - Test no blank glyphs generated
  - Test no saturated glyphs (all white)

---

## Phase 11: End-to-End Integration (Depends on: All Phases)

### 11.1 Generation Pipeline
- [ ] Implement `src/generate.py`:
  - Load trained model
  - Generate glyphs for given character sequence
  - Apply personality style_z
  - Save output images

### 11.2 Training + Online Learning Pipeline
- [ ] Implement `src/run_training.py`:
  - Base training from Open Sans data
  - Periodic evaluation with Claude feedback
  - Online learning updates
  - Run persistence

### 11.3 Demo Application
- [ ] Implement `src/demo.py`:
  - Generate "The Revolution Will Not Be Televised" with selected personality
  - Display/save glyph sequence
  - Interactive personality selection

### 11.4 Integration Tests
- [ ] Create `tests/test_integration.py`:
  - Full pipeline: train -> generate -> evaluate -> update
  - Verify personality consistency across glyphs
  - Verify run persistence across restarts

---

## Implementation Order Summary

1. **Phase 1**: Project Foundation (no deps) - START HERE
2. **Phases 2, 3**: Data Pipeline + Core Network (parallel, depend on Phase 1)
3. **Phase 4**: Persistence Layer (depends on Phase 3)
4. **Phase 5**: Training Pipeline (depends on Phases 2, 3, 4)
5. **Phases 6, 7**: Personality + Inference Optimization (parallel, depend on Phase 5 / Phase 3)
6. **Phase 8**: Claude Feedback Integration (depends on Phases 4, 6)
7. **Phase 9**: Online Learning (depends on Phases 5, 8)
8. **Phase 10**: Readability Validation (depends on Phases 3, 5)
9. **Phase 11**: End-to-End Integration (depends on all)

---

## Risk Areas

1. **Training Data Quality**: Open Sans rendering must produce high-quality, recognizable characters
2. **Inference Performance**: May require profiling and optimization to hit 5ms target
3. **Claude API Costs**: Each evaluation run requires 3+ API calls with vision
4. **Online Learning Stability**: REINFORCE can have high variance; baseline tuning critical
5. **Readability vs. Style Trade-off**: Extreme personalities may hurt recognition accuracy

---

## Success Criteria

- [ ] 14,040 training samples generated and validated
- [ ] GlyphNetwork produces 128x128 outputs in [0, 1] range
- [ ] Model size < 2.9M parameters
- [ ] Single inference < 5ms on RTX 3090
- [ ] Claude feedback successfully collected and parsed
- [ ] Online learning improves personality match scores over iterations
- [ ] Generated glyphs maintain > 95% human recognition accuracy
- [ ] Full run history persisted in networks/[id]/runs/ structure
