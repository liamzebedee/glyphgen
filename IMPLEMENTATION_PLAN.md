# Implementation Plan: Generative Font Renderer

> Generated by Ralph Planning Mode via OpenProse VM

## Current State

- [x] **Directory structure created** - src/, tests/, data/, networks/, outputs/, fonts/
- [x] **Dependencies defined** - requirements.txt created
- [x] **Config system** - src/config.py with all hyperparameters
- [x] **Utilities** - src/utils.py with device detection, checkpointing
- [x] **Training data generated** - 14,040 samples saved to data/train_dataset.pt (877.7 MB)
- [ ] **No model weights** - Must train from scratch

## Specs Reference

All specs in `specs/`:
- `glyph-network.md` - Neural network architecture
- `training-data.md` - Dataset generation
- `personality-expression.md` - 64-dim style_z
- `context-awareness.md` - prev_char influence
- `inference-performance.md` - <5ms latency
- `readability-guarantees.md` - 95%+ recognition
- `online-learning.md` - REINFORCE updates
- `feedback-collection.md` - Claude evaluation
- `weight-update-strategy.md` - Gradient computation
- `model-persistence.md` - networks/[id]/runs/

---

## Phase 1: Project Foundation (No Dependencies)

### 1.1 Project Structure Setup
- [x] Create `src/` directory with `__init__.py`
- [x] Create `tests/` directory with `__init__.py`
- [x] Create `data/` directory for training data
- [x] Create `networks/` directory for model persistence
- [x] Create `outputs/` directory for demo output
- [x] Create `fonts/` directory for Open Sans

> Note: Using single-file modules per AGENTS.md pattern instead of subdirectories.
> Files: glyphnet.py, generate_dataset.py, train.py, demo.py, online_learn.py

### 1.2 Dependency Management
- [x] Create `requirements.txt` with PyTorch 2.0+, Pillow, numpy, anthropic, etc.

### 1.3 Configuration System
- [x] Create `src/config.py` with all hyperparameters (dataclass-based)
- [x] Create `src/utils.py` with device detection, checkpointing, slugify

### 1.4 Documentation
- [x] Create `AGENTS.md` with project conventions

**Phase 1 COMPLETE** ✓

---

## Phase 2: Data Pipeline (Depends on: Phase 1)

> Note: Tasks 2.1-2.4 were combined into a single `src/generate_dataset.py` file per the single-file module pattern in AGENTS.md.

### 2.1 Font Acquisition
- [x] Font downloaded to `fonts/OpenSans-Regular.ttf`

### 2.2 Character Rendering
- [x] Implemented in `src/generate_dataset.py`:
  - Render single character to 128x128 grayscale PIL Image
  - Center character in canvas with consistent padding
  - Support all 26 lowercase letters (a-z)
  - Validate rendered characters are non-blank

### 2.3 Augmentation Pipeline
- [x] Implemented in `src/generate_dataset.py`:
  - Rotation: [-15, 15] degrees
  - Scale: [0.8, 1.2] factor
  - Translation: [-5, 5] pixels both axes
  - Gaussian blur: kernel sizes [1, 3, 5]
  - Gaussian noise: std [0.01, 0.1]
  - Deterministic with seed control
  - Preserve 128x128 dimensions

### 2.4 Dataset Generation
- [x] Implemented as `src/generate_dataset.py`:
  - Generated 14,040 samples (26 chars x 27 contexts x 20 augmentations)
  - Created tensors: images (14040, 1, 128, 128), prev_chars (14040,), curr_chars (14040,)
  - Saved to `data/train_dataset.pt` (877.7 MB)
  - Reproducible with fixed seed
  - Progress logging included

### 2.5 Dataset Loader
- [ ] Implement `src/data/dataset.py`:
  - PyTorch Dataset class wrapping the .pt file
  - DataLoader factory with configurable batch size
  - Validation split support

### 2.6 Data Tests
- [ ] Create `tests/test_data_pipeline.py`:
  - Test font loading
  - Test character rendering produces non-blank images
  - Test augmentations preserve dimensions
  - Test dataset shapes and value ranges
  - Test reproducibility with fixed seed

---

## Phase 3: Core Neural Network (Depends on: Phase 1)

> Note: Per AGENTS.md single-file pattern, implemented as `src/glyphnet.py` instead of separate files in `src/models/`.

### 3.1-3.4 GlyphNetwork Implementation
- [x] Implemented `src/glyphnet.py` with:
  - PrevCharEmbedding: 27 tokens x 32 dims (token 0 = start)
  - CurrCharEmbedding: 27 tokens x 32 dims
  - Input validation for token ranges
  - MLP fusion: 128 -> 256 -> 512 -> 256 -> 512
  - Decoder projection: 512 -> 2048 (reshape to 8x8x32)
  - TransposeConv decoder: 8x8 -> 128x128
  - Channel progression: 32 -> 64 -> 32 -> 16 -> 8 -> 1
  - Sigmoid output in [0, 1]
  - Parameter count: 1,555,777 (within 2.9M limit)
  - Forward: `forward(prev_char, curr_char, style_z) -> (B, 1, 128, 128)`

### 3.5 Model Tests
- [x] Created `tests/test_glyphnet.py` with 27 tests:
  - Input/output shapes (single and batch)
  - Output bounds [0, 1] including extreme styles
  - Input validation (valid ranges, rejects invalid)
  - Style variation produces different outputs
  - Character variation produces different outputs
  - All 26 characters produce distinct outputs
  - prev_char affects output
  - Determinism with fixed seed
  - Batch equals individual processing
  - Parameter count < 2.9M
  - CPU inference < 100ms
  - Edge cases (start token, repetition, not blank/saturated)

**Phase 3 COMPLETE** ✓

---

## Phase 4: Persistence Layer (Depends on: Phase 3)

### 4.1 Directory Management
- [ ] Implement `src/utils/persistence.py`:
  - Create `networks/[id]/runs/` directory structure
  - Font ID validation: `{number}-{name}` pattern, lowercase only
  - Unique run ID generation (ISO 8601 timestamps with microseconds)
  - Directory discovery on startup

### 4.2 Weight Serialization
- [ ] Implement weight save/load in `src/utils/persistence.py`:
  - `save_model(font_id, weights, personality_vector, sample_image, eval_glyphs, feedback)`
  - `load_model(font_id, run_id=None)` - defaults to latest run
  - Version metadata in saved files
  - Atomic saves (temp file + rename)
  - Corruption detection on load

### 4.3 Run Management
- [ ] Implement run tracking:
  - `list_fonts()` -> List[str]
  - `list_runs(font_id)` -> List[RunMetadata]
  - `get_run_info(font_id, run_id)` -> RunMetadata
  - Chronological ordering of runs
  - Handle incomplete runs gracefully

### 4.4 Persistence Tests
- [ ] Create `tests/test_persistence.py`:
  - Test directory creation
  - Test save/load round-trip numerical equivalence (6 decimal places)
  - Test font ID validation
  - Test run discovery
  - Test corruption detection
  - Test concurrent access safety

---

## Phase 5: Training Pipeline (Depends on: Phases 2, 3, 4)

### 5.1 Loss Functions
- [ ] Implement `src/training/losses.py`:
  - Reconstruction loss (MSE or BCE for pixel values)
  - Edge-aware loss for sharp glyph boundaries
  - Style diversity regularization (optional)

### 5.2 Base Trainer
- [ ] Implement `src/training/trainer.py`:
  - Training loop with DataLoader
  - Optimizer setup (AdamW recommended)
  - Learning rate scheduling
  - Checkpoint saving via persistence layer
  - Logging of loss curves and metrics
  - GPU/CPU device management

### 5.3 Training Script
- [ ] Create `src/train.py`:
  - CLI interface for training
  - Config loading
  - Dataset initialization
  - Model initialization
  - Training execution
  - Final checkpoint save

### 5.4 Training Tests
- [ ] Create `tests/test_training.py`:
  - Test loss computation
  - Test single training step
  - Test checkpoint save/resume
  - Test training loop runs without error

---

## Phase 6: Personality Expression (Depends on: Phase 5)

### 6.1 Style Latent Interface
- [ ] Implement `src/models/style.py`:
  - StyleVector class: 64-dim float tensor
  - Random initialization
  - Interpolation between styles
  - L2 norm clamping for stability
  - Save/load style vectors

### 6.2 Personality Definitions
- [ ] Create `configs/personalities.yaml`:
  - Define personality names: fruity, aggressive, elegant, dumb, etc.
  - Map to initial style_z seeds or learned vectors

### 6.3 Personality Tests
- [ ] Create `tests/test_personality.py`:
  - Test style_z dimensionality = 64
  - Test interpolation produces smooth transitions
  - Test zero vector produces valid output
  - Test cross-glyph consistency with same style_z

---

## Phase 7: Inference Optimization (Depends on: Phase 3)

### 7.1 GPU Optimization
- [ ] Implement `src/inference/engine.py`:
  - CUDA device placement
  - torch.compile() for graph optimization
  - Pre-allocated buffer pool
  - Warmup inference on model load

### 7.2 Batched Inference
- [ ] Implement batch processing:
  - Dynamic batch size support (1-32)
  - Sub-linear per-glyph latency scaling
  - Memory-efficient batch handling

### 7.3 Performance Benchmarks
- [ ] Create `tests/benchmark_inference.py`:
  - Single-glyph latency test (< 5ms on RTX 3090)
  - Batch efficiency test (batch of 8 <= 60% per-glyph latency)
  - Memory usage test (< 500MB single, < 2GB batch of 8)
  - Throughput test (>= 200 glyphs/second)
  - 10,000 consecutive inference stress test

---

## Phase 8: Claude Feedback Integration (Depends on: Phases 4, 6)

### 8.1 Image Encoding
- [ ] Implement `src/evaluation/image_encoding.py`:
  - Convert glyph tensor to PNG bytes
  - Base64 encode for API transmission
  - Validate encoding fidelity

### 8.2 Claude Vision API Client
- [ ] Implement `src/evaluation/claude_feedback.py`:
  - Initialize Anthropic client with API key
  - Send base64 image with personality rating prompt
  - Parse 1-10 ratings from Claude response
  - Handle API errors: timeout, rate limit, auth failure
  - Retry logic with exponential backoff

### 8.3 Feedback Prompt Engineering
- [ ] Create prompts for personality dimensions:
  - Fruity: "Rate how fruity this glyph is (1=minimal, 10=extremely). Consider curves, roundness, playful characteristics."
  - Aggressive: "Rate aggression (1=minimal, 10=extreme). Consider sharp angles, boldness, tension."
  - Additional dimensions as needed

### 8.4 Feedback Storage
- [ ] Implement feedback persistence:
  - Save to `networks/[id]/runs/N_eval_X_glyph-[char]_feedback.txt`
  - JSON format with ratings, timestamp, model metadata
  - Append without overwriting previous feedback

### 8.5 Feedback Tests
- [ ] Create `tests/test_feedback.py`:
  - Test image encoding round-trip
  - Test feedback file creation and format
  - Mock Claude API for deterministic tests
  - Test error handling for API failures

---

## Phase 9: Online Learning (Depends on: Phases 5, 8)

### 9.1 REINFORCE Implementation
- [ ] Implement `src/training/reinforce.py`:
  - `compute_policy_gradient(feedback_scores, style_z, log_probs)` -> gradients
  - Advantage computation: rating - baseline
  - Gradient scaling by advantage

### 9.2 EMA Baseline Tracker
- [ ] Implement `src/training/baseline.py`:
  - Exponential moving average: baseline = alpha * rating + (1-alpha) * baseline
  - Configurable alpha (default 0.9-0.99)
  - Initialization strategy
  - Save/load baseline state

### 9.3 Weight Update Strategy
- [ ] Implement `src/training/weight_updater.py`:
  - Apply gradient updates to style_z and decoder layers
  - Gradient clipping (L2 norm threshold)
  - Learning rate control
  - Update only specified layers (final 2-3 decoder layers)

### 9.4 Online Learning Integration
- [ ] Implement `src/training/online_learner.py`:
  - Full cycle: rating -> advantage -> gradient -> update -> checkpoint
  - Update within 500ms budget
  - Memory overhead < 50MB
  - Checkpoint to `networks/[id]/runs/[run_id]/weights_v[N].pt`
  - Log gradients, losses, weight statistics

### 9.5 Online Learning Tests
- [ ] Create `tests/test_online_learning.py`:
  - Test advantage computation
  - Test baseline EMA convergence
  - Test gradient stability (no NaN/Inf)
  - Test weight update direction matches advantage sign
  - Test checkpoint versioning

---

## Phase 10: Readability Validation (Depends on: Phases 3, 5)

### 10.1 Edge Detection Metrics
- [ ] Implement `src/evaluation/readability.py`:
  - Edge sharpness score via gradient magnitude
  - Mean gradient threshold > 0.7

### 10.2 Glyph Metrics
- [ ] Implement glyph measurement:
  - X-height, cap-height, stroke width
  - Comparison against Open Sans reference (within +/- 15%)

### 10.3 Automated Recognition (Optional)
- [ ] Implement OCR validation:
  - Use pretrained character classifier
  - Validate generated glyphs are recognizable
  - Target: > 95% accuracy

### 10.4 Readability Tests
- [ ] Create `tests/test_readability.py`:
  - Test edge sharpness metric
  - Test glyph metrics within tolerance
  - Test no blank glyphs generated
  - Test no saturated glyphs (all white)

---

## Phase 11: End-to-End Integration (Depends on: All Phases)

### 11.1 Generation Pipeline
- [ ] Implement `src/generate.py`:
  - Load trained model
  - Generate glyphs for given character sequence
  - Apply personality style_z
  - Save output images

### 11.2 Training + Online Learning Pipeline
- [ ] Implement `src/run_training.py`:
  - Base training from Open Sans data
  - Periodic evaluation with Claude feedback
  - Online learning updates
  - Run persistence

### 11.3 Demo Application
- [ ] Implement `src/demo.py`:
  - Generate "The Revolution Will Not Be Televised" with selected personality
  - Display/save glyph sequence
  - Interactive personality selection

### 11.4 Integration Tests
- [ ] Create `tests/test_integration.py`:
  - Full pipeline: train -> generate -> evaluate -> update
  - Verify personality consistency across glyphs
  - Verify run persistence across restarts

---

## Implementation Order Summary

1. **Phase 1**: Project Foundation (no deps) - START HERE
2. **Phases 2, 3**: Data Pipeline + Core Network (parallel, depend on Phase 1)
3. **Phase 4**: Persistence Layer (depends on Phase 3)
4. **Phase 5**: Training Pipeline (depends on Phases 2, 3, 4)
5. **Phases 6, 7**: Personality + Inference Optimization (parallel, depend on Phase 5 / Phase 3)
6. **Phase 8**: Claude Feedback Integration (depends on Phases 4, 6)
7. **Phase 9**: Online Learning (depends on Phases 5, 8)
8. **Phase 10**: Readability Validation (depends on Phases 3, 5)
9. **Phase 11**: End-to-End Integration (depends on all)

---

## Risk Areas

1. **Training Data Quality**: Open Sans rendering must produce high-quality, recognizable characters
2. **Inference Performance**: May require profiling and optimization to hit 5ms target
3. **Claude API Costs**: Each evaluation run requires 3+ API calls with vision
4. **Online Learning Stability**: REINFORCE can have high variance; baseline tuning critical
5. **Readability vs. Style Trade-off**: Extreme personalities may hurt recognition accuracy

---

## Success Criteria

- [ ] 14,040 training samples generated and validated
- [ ] GlyphNetwork produces 128x128 outputs in [0, 1] range
- [ ] Model size < 2.9M parameters
- [ ] Single inference < 5ms on RTX 3090
- [ ] Claude feedback successfully collected and parsed
- [ ] Online learning improves personality match scores over iterations
- [ ] Generated glyphs maintain > 95% human recognition accuracy
- [ ] Full run history persisted in networks/[id]/runs/ structure
