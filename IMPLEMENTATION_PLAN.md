# Implementation Plan: Generative Font Renderer

> Generated by Ralph Planning Mode via OpenProse VM

## Current State

- [x] **Directory structure created** - src/, tests/, data/, networks/, outputs/, fonts/
- [x] **Dependencies defined** - requirements.txt created
- [x] **Config system** - src/config.py with all hyperparameters
- [x] **Utilities** - src/utils.py with device detection, checkpointing
- [x] **Training data generated** - 14,040 samples saved to data/train_dataset.pt (877.7 MB)
- [x] **Training pipeline** - src/train.py with loss functions, training loop, CLI
- [x] **Model weights trained** - 100 epochs completed, best val loss 0.0294, saved to outputs/

## Specs Reference

All specs in `specs/`:
- `glyph-network.md` - Neural network architecture
- `training-data.md` - Dataset generation
- `personality-expression.md` - 64-dim style_z
- `context-awareness.md` - prev_char influence
- `inference-performance.md` - <5ms latency
- `readability-guarantees.md` - 95%+ recognition
- `online-learning.md` - REINFORCE updates
- `feedback-collection.md` - Claude evaluation
- `weight-update-strategy.md` - Gradient computation
- `model-persistence.md` - networks/[id]/runs/

---

## Phase 1: Project Foundation (No Dependencies)

### 1.1 Project Structure Setup
- [x] Create `src/` directory with `__init__.py`
- [x] Create `tests/` directory with `__init__.py`
- [x] Create `data/` directory for training data
- [x] Create `networks/` directory for model persistence
- [x] Create `outputs/` directory for demo output
- [x] Create `fonts/` directory for Open Sans

> Note: Using single-file modules per AGENTS.md pattern instead of subdirectories.
> Files: glyphnet.py, generate_dataset.py, train.py, demo.py, online_learn.py

### 1.2 Dependency Management
- [x] Create `requirements.txt` with PyTorch 2.0+, Pillow, numpy, anthropic, etc.

### 1.3 Configuration System
- [x] Create `src/config.py` with all hyperparameters (dataclass-based)
- [x] Create `src/utils.py` with device detection, checkpointing, slugify

### 1.4 Documentation
- [x] Create `AGENTS.md` with project conventions

**Phase 1 COMPLETE** ✓

---

## Phase 2: Data Pipeline (Depends on: Phase 1)

> Note: Tasks 2.1-2.4 were combined into a single `src/generate_dataset.py` file per the single-file module pattern in AGENTS.md.

### 2.1 Font Acquisition
- [x] Font downloaded to `fonts/OpenSans-Regular.ttf`

### 2.2 Character Rendering
- [x] Implemented in `src/generate_dataset.py`:
  - Render single character to 128x128 grayscale PIL Image
  - Center character in canvas with consistent padding
  - Support all 26 lowercase letters (a-z)
  - Validate rendered characters are non-blank

### 2.3 Augmentation Pipeline
- [x] Implemented in `src/generate_dataset.py`:
  - Rotation: [-15, 15] degrees
  - Scale: [0.8, 1.2] factor
  - Translation: [-5, 5] pixels both axes
  - Gaussian blur: kernel sizes [1, 3, 5]
  - Gaussian noise: std [0.01, 0.1]
  - Deterministic with seed control
  - Preserve 128x128 dimensions

### 2.4 Dataset Generation
- [x] Implemented as `src/generate_dataset.py`:
  - Generated 14,040 samples (26 chars x 27 contexts x 20 augmentations)
  - Created tensors: images (14040, 1, 128, 128), prev_chars (14040,), curr_chars (14040,)
  - Saved to `data/train_dataset.pt` (877.7 MB)
  - Reproducible with fixed seed
  - Progress logging included

### 2.5 Dataset Loader
- [x] Implemented `src/dataset.py`:
  - GlyphDataset class wrapping the .pt file
  - create_dataloaders() factory with train/val split
  - create_train_loader() for full dataset without split
  - Configurable batch size, workers, pin_memory
  - Reproducible splits with seed parameter

### 2.6 Data Tests
- [x] Created `tests/test_dataset.py` with 27 tests:
  - Dataset loading and sample access
  - Data shapes (image: 1x128x128, chars: scalar int64)
  - Value ranges (images: [0,1], prev_char: [0,26], curr_char: [1,26])
  - All 26 chars and 27 contexts represented
  - DataLoader creation with train/val split
  - Batch shapes and dtypes
  - Shuffle behavior (train shuffles, val deterministic)
  - Custom batch size and split ratio
  - Reproducibility with fixed seed
  - Data integrity and distribution validation

**Phase 2 COMPLETE** ✓

---

## Phase 3: Core Neural Network (Depends on: Phase 1)

> Note: Per AGENTS.md single-file pattern, implemented as `src/glyphnet.py` instead of separate files in `src/models/`.

### 3.1-3.4 GlyphNetwork Implementation
- [x] Implemented `src/glyphnet.py` with:
  - PrevCharEmbedding: 27 tokens x 32 dims (token 0 = start)
  - CurrCharEmbedding: 27 tokens x 32 dims
  - Input validation for token ranges
  - MLP fusion: 128 -> 256 -> 512 -> 256 -> 512
  - Decoder projection: 512 -> 2048 (reshape to 8x8x32)
  - TransposeConv decoder: 8x8 -> 128x128
  - Channel progression: 32 -> 64 -> 32 -> 16 -> 8 -> 1
  - Sigmoid output in [0, 1]
  - Parameter count: 1,555,777 (within 2.9M limit)
  - Forward: `forward(prev_char, curr_char, style_z) -> (B, 1, 128, 128)`

### 3.5 Model Tests
- [x] Created `tests/test_glyphnet.py` with 27 tests:
  - Input/output shapes (single and batch)
  - Output bounds [0, 1] including extreme styles
  - Input validation (valid ranges, rejects invalid)
  - Style variation produces different outputs
  - Character variation produces different outputs
  - All 26 characters produce distinct outputs
  - prev_char affects output
  - Determinism with fixed seed
  - Batch equals individual processing
  - Parameter count < 2.9M
  - CPU inference < 100ms
  - Edge cases (start token, repetition, not blank/saturated)

**Phase 3 COMPLETE** ✓

---

## Phase 4: Persistence Layer (Depends on: Phase 3)

> Note: Per AGENTS.md single-file pattern, implemented as `src/persistence.py` instead of `src/utils/persistence.py`.

### 4.1 Directory Management
- [x] Implemented `src/persistence.py`:
  - Create `networks/[id]/runs/` directory structure via `ensure_font_dirs()`
  - Font ID validation: `{number}-{name}` pattern, lowercase only via `validate_font_id()`
  - Unique run ID generation (ISO 8601 timestamps with microseconds) via `generate_run_id()`
  - Directory discovery on startup via `list_fonts()` and `list_runs()`

### 4.2 Weight Serialization
- [x] Implemented weight save/load in `src/persistence.py`:
  - `save_model(font_id, model, style_z, sample_image, eval_glyphs, feedback)` -> run_id
  - `load_model(font_id, model, run_id=None)` - defaults to latest run, returns (style_z, metadata)
  - Version metadata in saved files (`weights_version`, `feedback_schema`)
  - Atomic saves via `_atomic_save()` (temp file + rename)
  - Corruption detection on load with clear error messages

### 4.3 Run Management
- [x] Implemented run tracking:
  - `list_fonts()` -> List[str] - sorted alphabetically
  - `list_runs(font_id)` -> List[RunMetadata] - sorted chronologically
  - `get_run_info(font_id, run_id)` -> RunMetadata
  - `get_latest_run(font_id)` -> Optional[RunMetadata]
  - Handle incomplete runs gracefully (missing metadata handled)
  - Additional utilities: `load_feedback()`, `load_sample_image()`, `load_eval_glyphs()`, `export_style_z()`

### 4.4 Persistence Tests
- [x] Created `tests/test_persistence.py` with 42 tests:
  - Font ID validation (valid/invalid patterns)
  - Directory creation and structure
  - Save/load round-trip numerical equivalence (6 decimal places)
  - Run discovery and chronological ordering
  - Corruption detection (corrupted weights, missing keys, corrupted metadata)
  - Concurrent access safety (parallel saves to different fonts)
  - File existence checks and deletion operations
  - RunMetadata serialization/deserialization
  - Style vector export

**Phase 4 COMPLETE** ✓

---

## Phase 5: Training Pipeline (Depends on: Phases 2, 3, 4)

> Note: Per AGENTS.md single-file pattern, implemented as `src/train.py` instead of separate files.

### 5.1 Loss Functions
- [x] Implemented in `src/train.py`:
  - MSE reconstruction loss for pixel values
  - Edge-aware loss using Sobel gradient magnitude
  - Combined loss: `total = recon + edge_weight * edge`

### 5.2 Base Trainer
- [x] Implemented in `src/train.py`:
  - `train_one_epoch()` function with DataLoader iteration
  - AdamW optimizer with configurable weight decay
  - CosineAnnealingWarmRestarts scheduler with warmup
  - Checkpoint saving (best, periodic, final)
  - Loss logging per epoch (total, recon, edge)
  - Device management via `get_device()`

### 5.3 Training Script
- [x] Implemented `src/train.py`:
  - CLI with argparse: `--epochs`, `--resume`, `--output-dir`
  - Config loading from `src/config.py`
  - Dataset initialization via `create_dataloaders()`
  - Model initialization and parameter counting
  - Training execution with validation
  - Final checkpoint saved to `outputs/final_checkpoint.pt`

### 5.4 Training Tests
- [x] Created `tests/test_training.py` with 18 tests:
  - Loss computation (MSE, combined, edge weight)
  - Edge loss shape, positivity, gradient flow
  - Single training step updates weights
  - Validation step doesn't update weights
  - Gradient stability (no NaN/Inf)
  - Loss decreases over steps
  - Checkpoint save/resume round-trip
  - Full training loop runs for 1 epoch

**Phase 5 COMPLETE** ✓

---

## Phase 6: Personality Expression (Depends on: Phase 5)

> Note: Per AGENTS.md single-file pattern, implemented as `src/style.py` instead of `src/models/style.py`.

### 6.1 Style Latent Interface
- [x] Implemented `src/style.py`:
  - StyleVector dataclass: 64-dim float tensor with name
  - Creation methods: zeros(), random(seed, std), from_tensor(), load()
  - Interpolation: interpolate(other, t) for smooth transitions
  - L2 norm operations: norm(), clamp_norm(max), normalize(target)
  - Persistence: save(path), load(path) with multiple format support
  - Utilities: to(device), clone(), perturb(std, seed)
  - Helper functions: create_personality_vectors(), interpolate_personalities()

### 6.2 Personality Definitions
- [x] Personalities defined in `src/config.py`:
  - CONFIG.personalities = ["fruity", "dumb", "aggressive-sans"]
  - create_personality_vectors() generates seeded random vectors per personality
  - No separate YAML needed - config.py is the single source of truth

### 6.3 Personality Tests
- [x] Created `tests/test_style.py` with 53 tests:
  - StyleVector creation (zeros, random, from_tensor) with correct dimensions
  - Validation rejects wrong dimensions, 2D tensors, 0D tensors
  - Norm operations: calculation, clamping, normalization
  - Interpolation: t=0/0.5/1.0, rejects invalid t, smooth transitions
  - Persistence: save/load roundtrip, parent dir creation, legacy formats
  - Operations: to(), clone(), perturb(), equality, repr
  - create_personality_vectors(): creates unique, named, reproducible vectors
  - interpolate_personalities(): correct steps, endpoints match
  - Model integration: zero vector valid, deterministic, different styles differ

**Phase 6 COMPLETE** ✓

---

## Phase 7: Inference Optimization (Depends on: Phase 3)

> Note: Per AGENTS.md single-file pattern, implemented as `src/inference.py` instead of `src/inference/engine.py`.

### 7.1 GPU Optimization
- [x] Implemented `src/inference.py`:
  - InferenceEngine class with CUDA device placement via `get_device()`
  - torch.compile() for graph optimization (reduce-overhead mode)
  - BufferPool dataclass for pre-allocated tensor buffers
  - Warmup inference on model load (configurable iterations)

### 7.2 Batched Inference
- [x] Implemented batch processing in `src/inference.py`:
  - Dynamic batch size support (1-32, configurable max)
  - `generate_batch()` for efficient batch inference
  - `generate_sequence()` for text-to-glyph generation
  - Automatic chunking for batches exceeding max_batch_size
  - Sub-linear per-glyph latency via batch processing

### 7.3 Performance Benchmarks
- [x] Created `tests/test_inference.py` with 46 tests:
  - BufferPool: creation, shapes, views, batch size validation
  - Engine initialization: device placement, eval mode, warmup
  - Single glyph: shape, range, all chars, context, determinism
  - Batch inference: shape, range, shared style, equals single
  - Sequence generation: length, case-insensitive, context-aware
  - Performance: benchmark stats, latency reasonable, batch efficiency, throughput
  - Memory: no leaks, batch within budget (< 2GB)
  - Edge cases: empty sequence, batch size one, all prev_char contexts
  - StyleVector integration: object usage, different styles differ
  - Checkpoint loading: round-trip, preserves weights
  - Compilation: is_compiled property, compiled engine works

**Phase 7 COMPLETE** ✓

---

## Phase 8: Claude Feedback Integration (Depends on: Phases 4, 6)

### 8.1 Image Encoding
- [x] Implemented `src/image_encoding.py` (single-file per AGENTS.md pattern):
  - `tensor_to_pil()` - Convert glyph tensor (1, H, W) or (H, W) to PIL Image
  - `pil_to_base64()` - Encode PIL Image to base64 string (PNG default)
  - `tensor_to_base64()` - Direct tensor to base64 conversion
  - `base64_to_pil()` and `base64_to_tensor()` - Decoding for validation
  - `batch_to_base64()` - Batch encoding for multiple glyphs
  - `validate_encoding_fidelity()` - Round-trip validation within quantization tolerance
  - `get_media_type()` - MIME type mapping for API content type
  - 49 tests in `tests/test_image_encoding.py`

### 8.2 Claude Vision API Client
- [x] Implemented `src/feedback.py` (single-file per AGENTS.md pattern):
  - `ClaudeFeedbackClient` class with Anthropic client initialization
  - API key from environment variable (ANTHROPIC_API_KEY)
  - `evaluate_glyph()` - Send base64 image with personality rating prompt
  - `evaluate_batch()` - Batch evaluation with rate limit delay
  - `_parse_response()` - Parse 1-10 ratings from Claude JSON response
  - Error handling: timeout, rate limit (429), auth failure (401)
  - Retry logic with exponential backoff (up to 2 retries per spec)

### 8.3 Feedback Prompt Engineering
- [x] Implemented in `src/feedback.py`:
  - `PERSONALITY_PROMPTS` dict with detailed prompts for:
    - Fruity: curves, roundness, playful characteristics, organic flow
    - Aggressive: sharp angles, boldness, tension, confrontational energy
    - Dumb: irregularity, comic-like qualities, naive charm
    - Elegant: refinement, balance, sophistication, graceful proportions
  - `_build_prompt()` - Generates Claude prompt requesting JSON ratings
  - Configurable dimensions per evaluation

### 8.4 Feedback Storage
- [x] Implemented in `src/feedback.py`:
  - `FeedbackResult` dataclass for single glyph feedback
  - `EvaluationRun` dataclass for complete evaluation run
  - `save_feedback()` - Save to `networks/[id]/feedback/N_eval_X_glyph-[char]_feedback.txt`
  - `save_evaluation_run()` - Save run summary as JSON
  - `load_evaluation_run()` - Load saved run
  - `list_evaluation_runs()` - List all runs for a font
  - `compute_average_ratings()` - Aggregate ratings across runs
  - Feedback persists in JSON format with ratings, timestamp, model metadata

### 8.5 Feedback Tests
- [x] Created `tests/test_feedback.py` with 43 tests:
  - FeedbackResult/EvaluationRun serialization
  - Response parsing (JSON, code blocks, surrounding text)
  - Rating clamping and key normalization
  - ClaudeFeedbackClient API mocking
  - Retry logic and error handling (auth, rate limit, timeout)
  - Glyph sampling (correct size, no duplicates, determinism)
  - Feedback storage (save, load, list, next run number)
  - Collect feedback end-to-end with mocked API
  - Average rating computation

**Phase 8 COMPLETE** ✓

---

## Phase 9: Online Learning (Depends on: Phases 5, 8)

> Note: Per AGENTS.md single-file pattern, implemented as `src/online_learn.py` instead of separate files in `src/training/`.

### 9.1 REINFORCE Implementation
- [x] Implemented in `src/online_learn.py`:
  - `compute_policy_gradient()` - REINFORCE-style gradient from feedback
  - Advantage computation: rating - baseline
  - Gradient scaling by advantage magnitude and sign
  - Gradient clipping to max L2 norm

### 9.2 EMA Baseline Tracker
- [x] Implemented `BaselineTracker` class in `src/online_learn.py`:
  - Exponential moving average: baseline = alpha * rating + (1-alpha) * baseline
  - Configurable alpha (default 0.9)
  - Initialization to middle of 1-10 scale
  - Save/load baseline state via to_dict/from_dict
  - `is_reliable` property for minimum observations check

### 9.3 Weight Update Strategy
- [x] Implemented in `src/online_learn.py`:
  - `apply_style_update()` - Apply gradient to StyleVector with norm clamping
  - `apply_decoder_update()` - Update decoder layers with weight bounds
  - Gradient clipping (L2 norm threshold)
  - Learning rate control via CONFIG.online_lr
  - Update only final decoder layers (configurable target_layers)

### 9.4 Online Learning Integration
- [x] Implemented `OnlineLearner` class in `src/online_learn.py`:
  - Full cycle: rating -> advantage -> gradient -> update -> checkpoint
  - `update()` for single feedback, `update_batch()` for evaluation run
  - `OnlineLearningState` for persistent state across sessions
  - Checkpoint to `networks/[id]/runs/[run_id]/weights_v[N].pt`
  - `get_learning_stats()` for monitoring (advantage, gradient norms, etc.)
  - `finalize()` to complete session with metadata
  - `run_online_learning()` main entry point for CLI

### 9.5 Online Learning Tests
- [x] Created `tests/test_online_learning.py` with 33 tests:
  - TestBaselineTracker: EMA formula, convergence, serialization
  - TestGradientComputation: positive/negative advantage, clipping, no NaN/Inf
  - TestStyleUpdate: gradient application, norm clamping, name preservation
  - TestDecoderUpdate: parameter modification, weight bounds
  - TestCheckpointing: save/load versions, latest version detection
  - TestOnlineLearningState: creation, save/load persistence
  - TestOnlineLearner: initialization, single/batch updates, finalize, error handling
  - TestGradientStability: no NaN after many updates, bounded style_z
  - TestUpdateTiming: within 500ms budget

**Phase 9 COMPLETE** ✓

---

## Phase 10: Readability Validation (Depends on: Phases 3, 5)

> Note: Per AGENTS.md single-file pattern, implemented as `src/readability.py` instead of `src/evaluation/readability.py`.

### 10.1 Edge Detection Metrics
- [x] Implemented `src/readability.py`:
  - `compute_gradient_magnitude()` using Sobel filters
  - `compute_edge_sharpness()` returning 0-1 normalized score
  - `compute_edge_sharpness_batch()` for batch processing
  - Mean gradient threshold > 0.7 (EDGE_SHARPNESS_THRESHOLD constant)

### 10.2 Glyph Metrics
- [x] Implemented glyph measurement in `src/readability.py`:
  - `GlyphMetrics` dataclass: x_height, cap_height, stroke_width, descender_depth, ink_coverage
  - `compute_glyph_metrics()` measures structural properties
  - `compute_reference_deviation()` compares against Open Sans reference
  - `OPEN_SANS_REFERENCE` with baseline metrics for 128x128 glyphs
  - Threshold: ±15% variance (METRIC_VARIANCE_THRESHOLD constant)

### 10.3 Automated Recognition (Optional)
- [ ] Implement OCR validation:
  - Use pretrained character classifier
  - Validate generated glyphs are recognizable
  - Target: > 95% accuracy

### 10.4 Readability Tests
- [x] Created `tests/test_readability.py` with 54 tests:
  - TestGradientMagnitude: shape, non-negative, zero for constant, edge detection
  - TestEdgeSharpness: return type, range, low for smooth, high for edges, batch
  - TestGlyphMetrics: dataclass, blank image, ink coverage, cap height, stroke width, serialization
  - TestBlankSaturatedDetection: blank/saturated detection with thresholds
  - TestReferenceDeviation: zero for matching, positive for different, calculation accuracy
  - TestReadabilityResult: is_readable logic, serialization
  - TestValidateGlyphReadability: single glyph validation, blank/saturated detection
  - TestBatchValidation: batch processing, counts, ratios
  - TestReadabilitySummary: empty list, statistics computation
  - TestThresholdConstants: spec compliance (0.7 edge, 0.15 variance)
  - TestOpenSansReference: reasonable reference values

**Phase 10 COMPLETE** ✓ (10.3 OCR validation marked as optional, can be added later)

---

## Phase 11: End-to-End Integration (Depends on: All Phases)

### 11.1 Generation Pipeline
- [x] Implemented `src/generate.py`:
  - Load trained model via InferenceEngine
  - Generate glyphs for given character sequence via generate_sequence()
  - Apply personality style_z via StyleVector or raw tensor
  - Save output images (individual and composite)
  - Full CLI interface with argparse

### 11.2 Training + Online Learning Pipeline
- [ ] Implement `src/run_training.py`:
  - Base training from Open Sans data
  - Periodic evaluation with Claude feedback
  - Online learning updates
  - Run persistence

### 11.3 Demo Application
- [x] Implemented `src/demo.py`:
  - Generate "The Revolution Will Not Be Televised" with selected personality
  - Display/save glyph sequence (individual and composite)
  - Interactive personality selection via CLI
  - Support for all personalities with comparison image
  - Full CLI interface: `python -m src.demo --personality fruity`

### 11.4 Integration Tests
- [ ] Create `tests/test_integration.py`:
  - Full pipeline: train -> generate -> evaluate -> update
  - Verify personality consistency across glyphs
  - Verify run persistence across restarts

---

## Implementation Order Summary

1. **Phase 1**: Project Foundation (no deps) - START HERE
2. **Phases 2, 3**: Data Pipeline + Core Network (parallel, depend on Phase 1)
3. **Phase 4**: Persistence Layer (depends on Phase 3)
4. **Phase 5**: Training Pipeline (depends on Phases 2, 3, 4)
5. **Phases 6, 7**: Personality + Inference Optimization (parallel, depend on Phase 5 / Phase 3)
6. **Phase 8**: Claude Feedback Integration (depends on Phases 4, 6)
7. **Phase 9**: Online Learning (depends on Phases 5, 8)
8. **Phase 10**: Readability Validation (depends on Phases 3, 5)
9. **Phase 11**: End-to-End Integration (depends on all)

---

## Risk Areas

1. **Training Data Quality**: Open Sans rendering must produce high-quality, recognizable characters
2. **Inference Performance**: May require profiling and optimization to hit 5ms target
3. **Claude API Costs**: Each evaluation run requires 3+ API calls with vision
4. **Online Learning Stability**: REINFORCE can have high variance; baseline tuning critical
5. **Readability vs. Style Trade-off**: Extreme personalities may hurt recognition accuracy

---

## Success Criteria

- [ ] 14,040 training samples generated and validated
- [ ] GlyphNetwork produces 128x128 outputs in [0, 1] range
- [ ] Model size < 2.9M parameters
- [ ] Single inference < 5ms on RTX 3090
- [ ] Claude feedback successfully collected and parsed
- [ ] Online learning improves personality match scores over iterations
- [ ] Generated glyphs maintain > 95% human recognition accuracy
- [ ] Full run history persisted in networks/[id]/runs/ structure
